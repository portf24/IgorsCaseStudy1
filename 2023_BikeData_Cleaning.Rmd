---
title: 'Project for ‘Cyclistic’, Part 1: Data Cleaning'
author: "Igor Vysochanskyy"
date: "2024-03-31"
output: html_document
---

### This R Markdown cleans the 12 months (January-December) 2023 trip data of the Cyclistic bike-share company from the 12 zip files '2023(01-12)-divvy-tripdata.zip.'

#### URL for all  Cyclistic’s historical trip data: https://divvy-tripdata.s3.amazonaws.com/index.html

#### A comprehensive explanation of the data cleaning steps can be found in the Process Phase of the Project Description.

#### Install R packages & their libraries to enable subsequent operations.
#### Depending on your RStudio version, packages may be pre-installed, or you might need to install them manually.
```{r, message=FALSE}
library("tidyverse")
```

```{r}
library("skimr")
```


```{r}
library(httr)
```

### Introduction to streamlined approach to handling multiple .zip files directly from online sources. Specifically, it:
#### 1. Defines the base URL and file names for 12 monthly datasets.
#### 2. Initializes structures to manage data dynamically.
#### 3. Implements a loop to:
- Download .zip files from the provided URL into memory;
- Extract .csv files without saving intermediate files locally;
- Read and store the extracted data frames in the R environment for data cleaning and analysis.

#### Define the base URL and file names
```{r}
base_url <- "https://divvy-tripdata.s3.amazonaws.com/"
file_names <- paste0(202301:202312, "-divvy-tripdata.zip")
```

#### Initialize an empty list to store the data frames
```{r}
all_data <- list()
```

#### Full Code for the Loop
```{r}
# Loop to download, extract, and read the files
for (file_name in file_names) {
  # Construct the full URL
  file_url <- paste0(base_url, file_name)
  
  # Download the .zip file into memory
  response <- httr::GET(file_url)
  
  # Check if the request was successful
  if (httr::status_code(response) == 200) {
    # Extract the .csv file from the .zip archive without saving it to disk
    temp_zip <- tempfile(fileext = ".zip")
    writeBin(httr::content(response, "raw"), temp_zip)
    
    # Unzip the content into a temporary directory
    temp_dir <- tempfile()
    unzip(temp_zip, exdir = temp_dir)
    
    # Find the extracted .csv file
    csv_file <- list.files(temp_dir, pattern = "\\.csv$", full.names = TRUE)
    
    # Check if the code is running interactively or being knitted
    if (interactive()) {
    data <- readr::read_csv(csv_file)  # Show column types in RStudio
    } else {
    data <- readr::read_csv(csv_file, show_col_types = FALSE)  # Suppress in     knitted output
  }
    all_data[[file_name]] <- data
    
    # Clean up temporary files
    unlink(temp_zip)
    unlink(temp_dir, recursive = TRUE)
    
    cat("Downloaded and read:", file_name, "\n")
  } else {
    cat("Failed to download:", file_name, "\n")
  }
}
```

#### Example of the column specification returned by the readr::read_csv() is only shown for December, 2023 to prevent cluttering knitted HTML output. 
- Rows: 224073 (Number of rows is different for each month) Columns: 13
- Column specification:
- Delimiter: ","
- chr  (7): ride_id, rideable_type, start_station_name, 
- dbl  (4): start_lat, start_lng, end_lat, end_lng
- dttm (2): started_at, ended_at
- Downloaded and read: 202312-divvy-tripdata.zip (In this example)

#### This column specification and metadata summary will be shown for each month when run the code and is used for initial data observation that allows to see how each column in each month data is formatted.

#### Initial data observation:
- Columns number: 13 is correct for each month;
- Columns type: Correct for each month. 

#### Combine the 12 Months Datasets into One Data Frame
```{r}
combined_data <- bind_rows(all_data)

# Check the combined data
head(combined_data)

```
#### Evaluation after initial observation of combined dataset:
- The head() function confirms that the dataset contains the expected variables;
- Each column's data type (character, numeric, datetime) matches the expected format;
- The first six rows of data show appropriate values according to their respective categories.

### Beginning of the Modification and Data Cleaning

#### Initial data selection with nine columns relevant for data cleaning and further analysis from the original dataset
```{r}
mid_clean_stage1 <- subset(combined_data, select = c(ride_id, started_at, ended_at, member_casual, rideable_type, start_station_name, end_station_name, start_station_id, end_station_id))
```

#### Create a column 'ride_length' to represent the trip duration in minutes rounded to two decimals.
```{r}
mid_clean_stage1$ride_length <- round(
  as.numeric(difftime(mid_clean_stage1$ended_at, mid_clean_stage1$started_at, units = "mins")),
  2
)
```

#### Add 'day_of_week' column from 'started_at'
```{r}
mid_clean_stage1$day_of_week <- format(mid_clean_stage1$started_at, "%a")

```

#### Examine the overall structure of the data, including column names, data types, and sample values.
#### Note: This includes the examination of two newly added columns.
```{r}
glimpse(mid_clean_stage1)
```


### Check the detailed statistics including missing values, values distribution and overall dataset cleanliness
```{r}
skim_without_charts(mid_clean_stage1)
```

### Checkpoints after glimpse() and skim_without_charts() outcome
#### Positive Observations:
- Number of rows = n_unique for ride_id column - no duplicates;
- Same number of characters (16) in ride_id column;
- Whitespace and empty cells: 0 in each column;
- Column names: Correct;
- Character length variation in column 'rideable_type', and four station-related columns (names and IDs) is normal for this data type;
- The 'ride_length' column is in the "difftime" (<drtn> - duration) format which is correct.

#### Data Issues to Address:
#### The First Issue:
- Completeness: missing values in four columns with station names and their IDs.

#### The Second Issue:
- The 'ride_length' column has outliers in both p0 (minimum: -16656.52 min) and p100 (maximum: 98,489.07 min) trip durations.

### Fixing the Two Data Cleanliness Issues:
#### The First Issue Approach: Since the classic bikes that were not docked have missing values in four station-related columns:
- Delete all rows with missing values in station names and IDs, except if 'rideable_type == electric_bike' and check the number of rows removed.
- A detailed explanation for this step can be found in the Process Phase section of the Project Description

#### The Second Issue Approach: Find and apply a reasonable trip duration trim range.


### The First Data Cleanliness Issue Fix:
#### Delete all rows according to the directions above and calculate the difference in rows removed
```{r}
# Store the initial row count
initial_row_count1 <- nrow(mid_clean_stage1)

# Filter the data
clean_miss_val <- mid_clean_stage1 %>%
  filter(
    (
      !is.na(start_station_name) & !is.na(end_station_name) & 
      !is.na(start_station_id) & !is.na(end_station_id)
    ) | 
    rideable_type == "electric_bike"
  )

# Calculate the difference in rows removed
rows_removed1 <- initial_row_count1 - nrow(clean_miss_val)

# Print the result
cat("Number of rows removed:", rows_removed1, "\n")
```

#### Preparation for fixing trip duration outliers:
#### Create a data frame with six key columns that will serve as the foundation for all subsequent data cleaning and analysis processes.
```{r}
mid_clean_stage2 <- subset(clean_miss_val, select = c(ride_id, started_at, day_of_week, ride_length, member_casual, rideable_type))
```

### Identifying a Reasonable Trip Duration Trim Range by Analyzing Distribution Percentiles:

#### Aggregation for Plot 1: Define the percentiles with smaller increments
```{r}
plot_percentiles <- seq(0, 0.1, by = 0.002)
plot_values <- quantile(subset(mid_clean_stage2, member_casual == "casual")$ride_length, 
                    probs = plot_percentiles)
```

#### Plot 1. Trip duration 0-10 minutes in percentiles for Casuals for general visualization.
```{r}
plot(plot_percentiles * 100, plot_values, type = "o", 
     xlab = "Percentiles", ylab = "Minutes", 
     main = "Percentiles of trip duration for casuals, 0-10 min.",
     ylim = c(0, 5))
grid(nx = 10, ny = 10, lty = 1, col = "gray", lwd = 1)
```

#### Tibble 1. Casuals' Trip Duration in the 1st to 5th Percentile Range:
#### This code computes specific low-end quantiles for analyzing the distribution of shorter ride lengths
```{r}
p01 <- seq(0.02, 0.05, by = 0.005)
values01 <- quantile(subset(mid_clean_stage2, member_casual == "casual")$ride_length, 
                    probs = p01)
```

#### Create a data frame with percentiles and values
```{r}
p01_df <- data.frame(Percentile = p01, Minutes = values01)
```

#### Print the 'Tibble 1' data frame for Casuals
```{r}
print(p01_df)
```

#### Tibble 2. Casuals' Trip Duration in the 97th to 100th Percentile Range:
#### Compute the quantiles in the 0.97 to 1 range
```{r}
p02 <- seq(0.97, 1, by = 0.005)
values02 <- quantile(subset(mid_clean_stage2, member_casual == "casual")$ride_length, 
                    probs = p02)
```

#### Create a data frame with percentiles and values and round the Minutes column to 2 decimal places
```{r}
p02_df <- data.frame(Percentile = p02, Minutes = values02)
p02_df$Minutes <- round(p02_df$Minutes, 2)
```

#### Print the 'Tibble 2' data frame for Casuals
```{r}
print(p02_df)
```

### Analyze Members and Casuals Ride Durations Separately for a Reasonable Trim Duration Range Using a Histogram.

#### Subset the the Members' data for the range from 0 to 5 minutes
```{r}
filtered_member <- mid_clean_stage2 %>%
  filter(
    member_casual == "member",
    ride_length >= 0 & ride_length <= 5
  )

```

#### Plot 2. Histogram for the distribution of Members' data within 0 to 5-minute intervals, using a bin width of 0.1 minutes.
```{r}
ggplot(filtered_member, aes(x = ride_length)) +
  geom_histogram(binwidth = 0.1, fill = "green", color = "black", alpha = 0.4, na.rm = TRUE) +
  labs(
    title = "Distribution of Ride Lengths for Member Riders (Up to 5 Minutes)",
    x = "Ride Length (minutes)",
    y = "Count of Rides"
  ) +
  xlim(0, 5) +  # Limit the x-axis to 0-100 minutes
  theme_minimal()
```


#### Subset the the Casuals' data for the range from 0 to 5 minutes
```{r}
filtered_casual <- mid_clean_stage2 %>%
  filter(
    member_casual == "casual",
    ride_length >= 0 & ride_length <= 5
  )

```

#### Plot 3. Histogram for the distribution of Casuals' data within 0 to 5-minute intervals, using a bin width of 0.1 minutes.
```{r}
ggplot(filtered_casual, aes(x = ride_length)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black", alpha = 0.4, na.rm = TRUE) +
  labs(
    title = "Distribution of Ride Lengths for Casual Riders (Up to 5 Minutes)",
    x = "Ride Length (minutes)",
    y = "Count of Rides"
  ) +
  xlim(0, 5) +  # Limit the x-axis to 0-100 minutes
  theme_minimal()
```

#### Conclusion: The duration trim range of 2 minutes to 12 hours (720 minutes) is considered reasonable.
- A comprehensive explanation of this can be found in the Process Phase of the Project Description.

### The Second Data Cleanliness Issue Fix:
#### Trim the 'ride_length' column within the range of 2 minutes to 12 hours, ensuring the range is relevant for analysis.
```{r}
# Store the initial row count
initial_row_count2 <- nrow(mid_clean_stage2)

trim_dur2023 <- mid_clean_stage2[(mid_clean_stage2$ride_length >= 2 & 
                      mid_clean_stage2$ride_length <=  720), ]
# Calculate the difference in rows removed
rows_removed2 <- initial_row_count2 - nrow(trim_dur2023)

# Print the result
cat("Number of rows removed:", rows_removed2, "\n")

```


### Plot 4. Visualizing Trip Counts to Identify Other Potential Outliers:
#### Add a new 'month' column without modifying 'started_at'
```{r}
trim_dur2023 <- trim_dur2023 %>%
  mutate(month = floor_date(as.Date(started_at), "month"))
```

#### Summarize trip counts by month and bike type
```{r}
trip_counts <- trim_dur2023 %>%
  group_by(month, rideable_type) %>%
  summarize(trip_count = n_distinct(ride_id), .groups = "drop")
```

#### Create the chart
```{r}
ggplot(trip_counts, aes(x = month, y = trip_count, fill = rideable_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Monthly Trip Counts by All Bike Types",
    x = "",
    y = "Trip Count",
    fill = "Bike Type"
  ) +
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


#### Conclusion from this chart observation:
- The trip count for docked bikes is negligible compared to other bike types and appears to be missing in September to December, 2023

#### Check for Missing Bike Types in Monthly Data:
#### Check the presence of each rideable_type in each month
```{r}
rideable_presence <- trim_dur2023 %>%
  group_by(month, rideable_type) %>%
  summarize(present = n() > 0, .groups = "drop") %>%
  pivot_wider(names_from = rideable_type, values_from = present, values_fill = FALSE)
```

#### Filter rows where any 'rideable_type' is FALSE
```{r}
false_presence <- rideable_presence %>%
  pivot_longer(-month, names_to = "rideable_type", values_to = "present") %>%
  filter(!present) %>%
  select(month, rideable_type)

# View the result
print(false_presence)
```

#### The 'docked_bike' is missing in four months: from September to December, 2023.

### Investigation of Docked Bike Behavior Exclusively in Microsoft Excel:
- The January, April, and August historical datasets were each uploaded into separate Excel workbooks.
- Data cleaning was performed after evaluations the data cleanliness in this R Markdown.
- Deleted all rows with missing values in four columns with station names and their ID’s, except if ‘rideable_type == electric_bike’.
- Created a columns 'ride_length' and 'day_of_week'.
- Trimmed trip duration outliers to within the range of 2 minutes to 12 hours.
- Analyzed the data using Excel Pivot Columns Charts and Pie Charts. Charts are shown in the Process Phase of the Project Description.
- Excel Pivot Columns Charts and Pie Charts revealed that “docked bikes” exhibited very different behavior—an extremely small count of rides and a significantly longer average trip duration—indicative of potential outliers.

#### Conclusion:
#### Since this group of individuals are outliers, and the docked bikes are no longer in service, all rows with 'docked_bikes' should be deleted.
#### The rationale for this decision is explained in the Process Phase of the Project Description.

#### Remove the column 'month' that was added and using temporarely for Plot 4 and subsequent codes.
```{r}
trim_dur2023 <- trim_dur2023 %>%
  select(-month)
```

### Data Cleaning after Analysis in Excel:
#### Remove rows where rideable_type = "docked_bike".
```{r}
# Store the initial row count
initial_row_count3 <- nrow(trim_dur2023)

data2023 <- trim_dur2023[trim_dur2023$rideable_type != "docked_bike", ]

# Calculate the difference in rows removed
rows_removed3 <- initial_row_count3 - nrow(data2023)

# Print the result
cat("Number of rows removed:", rows_removed3, "\n")

```

#### Quick data observation
```{r}
glimpse(data2023)
```

#### Save modified and cleaned dataset as .RData object, making it ready for the Analysis Phase.
```{r}
save(data2023, file = "data2023.RData")
```

